{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0353815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter total number of periods: 3\n",
      "Enter period duration in minutes: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from deepface import DeepFace\n",
    "import joblib\n",
    "import face_recognition\n",
    "import time\n",
    "\n",
    "class RealTimeFaceRecognizer:\n",
    "    def __init__(self, student_model_path, teacher_model_path):\n",
    "        self.student_model = joblib.load(student_model_path)\n",
    "        self.teacher_model = joblib.load(teacher_model_path)\n",
    "\n",
    "    def recognize_faces_and_emotions(self, video_capture, total_periods, period_duration):\n",
    "        # Create a directory to store period Excel files\n",
    "        os.makedirs('period_excel_files', exist_ok=True)\n",
    "\n",
    "        # Load teacher data from Excel file\n",
    "        teacher_data = pd.read_excel('teachers.xlsx')\n",
    "\n",
    "        # Dictionary to store the mode emotion for each student\n",
    "        mode_emotions = {}\n",
    "        students = []\n",
    "\n",
    "        for period_number in range(1, total_periods + 1):\n",
    "            student_emotions = {}\n",
    "\n",
    "            # Run detect_teacher for 10 seconds\n",
    "            teacher_name, teacher_subject = self.detect_teacher(video_capture, self.teacher_model, teacher_data, 10)\n",
    "            students.append(teacher_subject)\n",
    "\n",
    "            # Loop for the duration of the period\n",
    "            for _ in range(period_duration * 60):\n",
    "                # Capture frame-by-frame\n",
    "                ret, frame = video_capture.read()\n",
    "\n",
    "                # Convert the frame to RGB\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Find all the faces in the frame\n",
    "                face_locations = face_recognition.face_locations(rgb_frame)\n",
    "                face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "                # Loop through each face found in the frame\n",
    "                for face_encoding in face_encodings:\n",
    "                    # Perform face recognition\n",
    "                    predictions = self.student_model.predict([face_encoding])\n",
    "                    name = predictions[0]\n",
    "\n",
    "                    # Perform emotion detection\n",
    "                    try:\n",
    "                        emotion_results = DeepFace.analyze(rgb_frame, actions=['emotion'], enforce_detection=False)\n",
    "                        emotion = emotion_results[0]['dominant_emotion']\n",
    "                    except ValueError:\n",
    "                        emotion = \"Unknown\"\n",
    "\n",
    "                    # Add emotion to the dictionary\n",
    "                    if name in student_emotions:\n",
    "                        student_emotions[name].append(emotion)\n",
    "                    else:\n",
    "                        student_emotions[name] = [emotion]\n",
    "\n",
    "            # Convert student emotions to a DataFrame\n",
    "            emotions_df = pd.DataFrame.from_dict(student_emotions, orient='index')\n",
    "\n",
    "            # Write DataFrame to Excel file without column names\n",
    "            emotions_df.to_excel(f'period_excel_files/period_{period_number}_emotions.xlsx', header=False)\n",
    "\n",
    "            # Calculate mode emotion for each student\n",
    "            for student, emotions in student_emotions.items():\n",
    "                if student in mode_emotions:\n",
    "                    mode_emotions[student].append(max(set(emotions), key=emotions.count))\n",
    "                else:\n",
    "                    mode_emotions[student] = [max(set(emotions), key=emotions.count)]\n",
    "\n",
    "        # Create DataFrame for mode emotions\n",
    "        mode_df = pd.DataFrame.from_dict(mode_emotions, orient='index')\n",
    "\n",
    "        # Add column names for mode emotions DataFrame with subjects\n",
    "        mode_df.columns = [f'Period {i} - {students[i-1]}' for i in range(1, total_periods + 1)]\n",
    "        mode_df.index.name = 'Name'\n",
    "\n",
    "        # Write DataFrame to final Excel file\n",
    "        mode_df.to_excel('emotion_student.xlsx')\n",
    "\n",
    "    def detect_teacher(self, video_capture, model, teacher_data, total_time):\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            # Check if total_time has passed\n",
    "            if time.time() - start_time > total_time:\n",
    "                print(\"No teacher detected within the specified time.\")\n",
    "                return None, None\n",
    "\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            # Convert the frame from BGR color to RGB color (required for face_recognition library)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Find all the faces and face encodings in the current frame\n",
    "            face_locations = face_recognition.face_locations(rgb_frame)\n",
    "            face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "            # Loop through each face found in the frame\n",
    "            for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "                # Perform face recognition\n",
    "                predictions = model.predict([face_encoding])\n",
    "                name = predictions[0]\n",
    "\n",
    "                # Check if the recognized face exists in teacher data\n",
    "                teacher_info = teacher_data[teacher_data['Name'] == name]\n",
    "                if not teacher_info.empty:\n",
    "                    teacher_name = teacher_info['Name'].values[0]\n",
    "                    teacher_subject = teacher_info['Subject'].values[0]\n",
    "                    return teacher_name, teacher_subject\n",
    "\n",
    "                # Draw a rectangle around the face\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "                # Draw a label with the name above the face\n",
    "                cv2.rectangle(frame, (left, top - 35), (right, top), (0, 255, 0), cv2.FILLED)\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\n",
    "                cv2.putText(frame, name, (left + 6, top - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "            # Display the resulting frame\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            # If no face is detected, increase the scan time by 5 seconds\n",
    "            if len(face_locations) == 0 and time.time() - start_time >= total_time:\n",
    "                print(\"No face detected. Extending scanning time by 5 seconds.\")\n",
    "                start_time = time.time()\n",
    "                total_time += 5\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    student_model_path = \"students_trained_model.pkl\"  # Path to your student trained model\n",
    "    teacher_model_path = \"trained_model.pkl\"  # Path to your teacher trained model\n",
    "\n",
    "    # Initialize the camera\n",
    "    video_capture = cv2.VideoCapture(0)  # 0 for default camera, change it according to your camera setup\n",
    "\n",
    "    # Input total number of periods and period duration\n",
    "    total_periods = int(input(\"Enter total number of periods: \"))\n",
    "    period_duration = int(input(\"Enter period duration in minutes: \"))\n",
    "\n",
    "    # Perform real-time face recognition with emotion detection for each period\n",
    "    recognizer = RealTimeFaceRecognizer(student_model_path, teacher_model_path)\n",
    "    recognizer.recognize_faces_and_emotions(video_capture, total_periods, period_duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108da7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
